{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[homework]fashionmnist.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"NMCheeicN6WA","colab_type":"text"},"cell_type":"markdown","source":["<img src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\" width=500, height=450>\n","<h3 style=\"text-align: center;\"><b>Phystech School of Applied Mathematics and Informatics (PSAMI) MIPT</b></h3>"]},{"metadata":{"id":"Od3krQTwN6WC","colab_type":"text"},"cell_type":"markdown","source":["---"]},{"metadata":{"id":"qpC3W7t3N6WD","colab_type":"text"},"cell_type":"markdown","source":["<h2 style=\"text-align: center;\"><b>Practice: Clothes recognition</b></h2>"]},{"metadata":{"id":"70POspJQN6WE","colab_type":"text"},"cell_type":"markdown","source":["---"]},{"metadata":{"id":"FyQZmZ6eN6WF","colab_type":"text"},"cell_type":"markdown","source":["Welcome to the 6th lesson's practice!  \n","\n","We assume that you have already checked our lesson about Multilayer Neural Networks. Here we will learn how to train the MLP to recognize different clothes types."]},{"metadata":{"id":"ZkA4QXU8N6WG","colab_type":"text"},"cell_type":"markdown","source":["<h2 style=\"text-align: center;\"><b>FashionMNIST</b></h2>"]},{"metadata":{"id":"jB4sW72DN6WH","colab_type":"text"},"cell_type":"markdown","source":["<img src=\"https://emiliendupont.github.io/imgs/mnist-chicken/mnist-and-fashion-examples.png\">"]},{"metadata":{"id":"LZdwlEDQN6WJ","colab_type":"text"},"cell_type":"markdown","source":["On the right of the picture you can see the dataset we will work with: grasyscale images of clothes with 28x28 resolution. On the left is more \"common\" dataset to start with -- MNIST dataset of handwritten numbers. The methods that you will use here are applicable to all multiclass grayscale datasets (with low resolution)."]},{"metadata":{"id":"HSsM40-8N6WK","colab_type":"text"},"cell_type":"markdown","source":["<h3 style=\"text-align: center;\"><b>Original dataset: https://github.com/zalandoresearch/fashion-mnist#get-the-data</b></h3> "]},{"metadata":{"id":"CfRzi2ykN6WP","colab_type":"text"},"cell_type":"markdown","source":["<h2 style=\"text-align: center;\"><b>Data</b></h2>"]},{"metadata":{"id":"0AhRNGtRN6WQ","colab_type":"text"},"cell_type":"markdown","source":["We want to predict the clothes type label `y` given its grayscale image `X`. Let's load the data:"]},{"metadata":{"id":"RV0_MC0WskuC","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch\n","import torchvision"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nufwoMZysxqq","colab_type":"code","colab":{}},"cell_type":"code","source":["from torchvision import transforms\n","\n","BATCH_SIZE = 4\n","\n","transform = transforms.Compose([transforms.ToTensor()])\n","\n","trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, \n","                                             download=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, \n","                                          shuffle=True, num_workers=2)\n","\n","testset = torchvision.datasets.FashionMNIST(root='./data', train=False, \n","                                            download=True, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, \n","                                         shuffle=False, num_workers=2)\n","\n","classes = tuple(str(i) for i in range(10))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FA96pcI7vVXG","colab_type":"text"},"cell_type":"markdown","source":["Here we've downloaded the dataset from PyTorch using  `datasets` module, then we created the `DataLoader` instances for train and test sets separately. We use `transforms` to cast the input data into `torch.Tensor()` and have set the `batch_size` to be equal to 32. What is the batch size? Check out the 7th lecture of our course about training the neural networks!"]},{"metadata":{"id":"maxLUkBiN6aD","colab_type":"text"},"cell_type":"markdown","source":["---"]},{"metadata":{"id":"V8B46i_DN6aD","colab_type":"text"},"cell_type":"markdown","source":["**Mini-batch (or just \"batch\")** is the subset of the original dataset. Mini-batch usually has a small number of elements, e.g. 32, 64 or 128 (compared to thousands in the original dataset). In order to avoid ordinal dependencies in data (excluding time series data) batch is usually constructed with random sampling from the original dataset.\n","\n","The motivation for using batches instead of the full dataset is as follows: optimization methods such as SGD or Adam are too noisy when computed using only one element, and too computationally expensive when computed using the full dataset. That's why we use stochastic optimization with just a portion of the dataset"]},{"metadata":{"id":"Of0xskgZN6aF","colab_type":"text"},"cell_type":"markdown","source":["**One iteration** of the optimizer stands for the calculation with **one batch**.  \n","**One epoch** of the optimizer stands for the calculation of gradients for **all the batches (the whole training set)**. \n","\n","If we have 60000 objects and the batch_size = 64 then one epoch takes 60000 / 64 = 937,5 = 938 iterations."]},{"metadata":{"id":"TvVokp8KN6aF","colab_type":"text"},"cell_type":"markdown","source":["---"]},{"metadata":{"id":"Me2X3dSp1uED","colab_type":"code","colab":{}},"cell_type":"code","source":["trainloader.dataset.data.shape"],"execution_count":0,"outputs":[]},{"metadata":{"id":"s0QjBwm91zww","colab_type":"code","colab":{}},"cell_type":"code","source":["testloader.dataset.data.shape"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TNAJZ6ai16Eh","colab_type":"text"},"cell_type":"markdown","source":["Let's see the first image:"]},{"metadata":{"id":"n5-ofq8V12hv","colab_type":"code","colab":{}},"cell_type":"code","source":["# torch.Tensor to numpy array\n","numpy_img = trainloader.dataset.data[0].numpy()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Yl9v-IIo18Bt","colab_type":"code","colab":{}},"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","plt.imshow(numpy_img);"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nVCtGFmV2Kqk","colab_type":"code","colab":{}},"cell_type":"code","source":["# play aroung with this cell to draw a random image\n","i = np.random.randint(low=0, high=60000)\n","\n","plt.imshow(trainloader.dataset.data[i].numpy(), cmap='gray');"],"execution_count":0,"outputs":[]},{"metadata":{"id":"j9dzicYY3EsN","colab_type":"text"},"cell_type":"markdown","source":["We can iterate over the dataloader this way:"]},{"metadata":{"id":"sVBJZb6h3ETD","colab_type":"code","colab":{}},"cell_type":"code","source":["for data in trainloader:\n","    print(data)\n","    break"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_y0LbAxUN6ZQ","colab_type":"text"},"cell_type":"markdown","source":["<h2 style=\"text-align: center;\"><b>PyTorch Neural Network for clothes recognition</b></h2>"]},{"metadata":{"id":"oqq4q-VEN6Z5","colab_type":"text"},"cell_type":"markdown","source":["Implement the architecture of your neural network:"]},{"metadata":{"id":"wxobP7YqN6Z6","colab_type":"code","colab":{}},"cell_type":"code","source":["net = torch.nn.Sequential(\n","    ???\n",")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bcjQT5ba55Oh","colab_type":"text"},"cell_type":"markdown","source":["Multiclass classification loss:"]},{"metadata":{"id":"uvkVv7se54uT","colab_type":"code","colab":{}},"cell_type":"code","source":["loss_fn = torch.nn.CrossEntropyLoss(size_average=False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zww0a9wEN6aI","colab_type":"text"},"cell_type":"markdown","source":["We are ready to train the network (Hint: check the seminar materials):"]},{"metadata":{"scrolled":true,"id":"90ub8cAQN6aJ","colab_type":"code","colab":{}},"cell_type":"code","source":["NUM_EPOCHS = 100\n","\n","learning_rate = 1e-4\n","optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n","\n","for epoch_num in range(NUM_EPOCHS):\n","    for X_batch, y_batch in trainloader:\n","        \n","        # bathc generator returns iamges as matrices\n","        # for MLP we need pixels to be the row-feature-vector\n","        # so we \"unroll\" each image 28x28 in 784-dimesional vector\n","        X_batch = X_batch.view(BATCH_SIZE, -1)\n","            \n","        # forward pass\n","        <Your code here>\n","\n","        # backward pass\n","        <Your code here>"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DTqAjXzJN6aL","colab_type":"text"},"cell_type":"markdown","source":["We've trained our network. Let's see per class accuracy on the training set:"]},{"metadata":{"id":"XgUc3qNPN6aM","colab_type":"code","colab":{}},"cell_type":"code","source":["class_correct = list(0. for i in range(10))\n","class_total = list(0. for i in range(10))\n","\n","classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n","           'Sandal', 'Shirt', 'Sneaker','Bag', 'Ankle boot']\n","\n","with torch.no_grad():\n","    for X_batch, y_batch in trainloader:\n","        y_pred = net(X_batch.view(BATCH_SIZE, -1))\n","        _, predicted = torch.max(y_pred, 1)\n","        c = (predicted == y_batch).squeeze()\n","        for i in range(len(y_pred)):\n","            label = y_batch[i]\n","            class_correct[label] += c[i].item()\n","            class_total[label] += 1\n","\n","for i in range(10):\n","    print('Accuracy of %5s : %2d %%' % (\n","        classes[i], 100 * class_correct[i] / class_total[i]))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"uqqq27QB7-Mc","colab_type":"text"},"cell_type":"markdown","source":["And on the test set:"]},{"metadata":{"id":"2yK_YA4I7-Rl","colab_type":"code","colab":{}},"cell_type":"code","source":["class_correct = list(0. for i in range(10))\n","class_total = list(0. for i in range(10))\n","\n","classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n","           'Sandal', 'Shirt', 'Sneaker','Bag', 'Ankle boot']\n","\n","with torch.no_grad():\n","    for X_batch, y_batch in testloader:\n","        y_pred = net(X_batch.view(BATCH_SIZE, -1))\n","        _, predicted = torch.max(y_pred, 1)\n","        c = (predicted == y_batch).squeeze()\n","        for i in range(len(y_pred)):\n","            label = y_batch[i]\n","            class_correct[label] += c[i].item()\n","            class_total[label] += 1\n","\n","for i in range(10):\n","    print('Accuracy of %5s : %2d %%' % (\n","        classes[i], 100 * class_correct[i] / class_total[i]))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"svjwails8Ywt","colab_type":"text"},"cell_type":"markdown","source":["Try to tune hyperparameters and the network architecture to reach 0.9+ quality for each class!"]},{"metadata":{"id":"x134iQKI-Cq9","colab_type":"text"},"cell_type":"markdown","source":["#### Oprional task"]},{"metadata":{"id":"omxJQBZq-Jq3","colab_type":"text"},"cell_type":"markdown","source":["Implement the function that takes as input the index of the image in the training set and prints the image and the neural network's prediction for this image."]},{"metadata":{"id":"ybN90Qza-Cvx","colab_type":"code","colab":{}},"cell_type":"code","source":["def visualize(index):\n","    <Your code here>"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AaF5jzTh-lNR","colab_type":"code","colab":{}},"cell_type":"code","source":["# Test the function here"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pLMP3KWV-o1N","colab_type":"text"},"cell_type":"markdown","source":["---"]},{"metadata":{"id":"dDmF_jAU8mP5","colab_type":"text"},"cell_type":"markdown","source":["**Thresholds for points for this hometask will be published on Canvas.**"]},{"metadata":{"id":"mSbtlXRPN6bK","colab_type":"text"},"cell_type":"markdown","source":["<h3 style=\"text-align: center;\"><b>Further reading</b></h3>"]},{"metadata":{"id":"XgpqlTX4N6bK","colab_type":"text"},"cell_type":"markdown","source":["*Kaggle kernels for FashionMNIST: https://www.kaggle.com/zalando-research/fashionmnist/kernels*"]}]}