{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H3DhPViKKByC"
   },
   "source": [
    "<img src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\" width=500, height=450>\n",
    "<h3 style=\"text-align: center;\"><b>Phystech School of Applied Mathematics and Informatics (PSAMI) MIPT</b></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center;\"><b>k Nearest Neighbor(KNN)</b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Neighbor Neighbor Method (kNN) is a very popular classification method, also sometimes used in regression tasks. This is one of the most understandable approaches to classification. The essence of the method is intuitive: you are like others, that is, your neighbors. Formally, the basis of the method is the compactness hypothesis: if the metric of the distance between the examples is introduced quite successfully, then similar examples are more often in the same class than in the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://hsto.org/web/68d/a45/6f0/68da456f00f8434e87628dbe7e3f54a7.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To classify each of the test sample objects, you must perform the following operations sequentially.:\n",
    "\n",
    "* Calculate the distance to each of the objects of the training sample\n",
    "* Select the objects of the training sample, to which the distance is minimal\n",
    "* The class of the object being classified is the class most often found among $k$ nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T2docs4225pb"
   },
   "source": [
    "We will work with a subsample of [forest coverage type data from the UCI repository](http://archive.ics.uci.edu/ml/datasets/Covertype).(subsample is `forest_dataset.csv`) Available in 7 different classes. Each object is described by 54 signs, 40 of which are binary. Data description is available here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "rvPrVRvK25pc"
   },
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('forest_dataset.csv',)\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "itCWxHEY25pg"
   },
   "source": [
    "Extract the values of the class label to the variable `labels`, attribute descriptions to the variable `feature_matrix`. Change the format to `numpy`-format using the method`.values`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "f_YIUOuV25ph"
   },
   "outputs": [],
   "source": [
    "labels = all_data[all_data.columns[-1]].values\n",
    "feature_matrix = all_data[all_data.columns[:-1]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BGn7U05I25pw"
   },
   "source": [
    "Now we will work with all 7 types of coverage. Divide the sample into training and test using the method `train_test_split`, use parameter values `test_size=0.2`, `random_state=42`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Q030jzyY25pl"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_matrix, test_feature_matrix, train_labels, test_labels = train_test_split('''your code''')\n",
    "\n",
    "# normalize data on normalization parameters for train_feature_matrix\n",
    "scaler = '''your code'''\n",
    "train_feature_matrix = scaler.'''your code'''(train_feature_matrix)\n",
    "test_feature_matrix = scaler.'''your code'''(test_feature_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quality of classification and regression by the method of nearest neighbors depends on several parameters:\n",
    "\n",
    "* the number of the neighbors `n_neighbors`\n",
    "* the object distance metric `metric`\n",
    "* the weights of neighbors (the neighbors of the test example may enter with different weights, for example, the further the example is, the less its voice is taken into account) `weights`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BHVNCaJ325qD"
   },
   "source": [
    "Teach in the dataset `KNeighborsClassifier` from the `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "o4CMnnOY25qD"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit('''your code''')\n",
    "pred_labels = clf.predict('''your code''')\n",
    "accuracy_score(test_labels, '''your code''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1:\n",
    "* What quality have you got?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look through the parameters of our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8WzoRJZd25qF"
   },
   "source": [
    "* Go through the grid from `1` to` 10` parameter of the number of the neighbors\n",
    "\n",
    "* Also you try using different metrics: `['manhattan', 'euclidean']`\n",
    "\n",
    "* Try different weighting strategies.: `[‘uniform’, ‘distance’]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "4lMSy-6f25qG",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {'weights': ['''your code'''], 'n_neighbors': '''your code''', 'metric': ['''your code''']}\n",
    "\n",
    "# Docstring:     \n",
    "# Exhaustive search over specified parameter values for an estimator.\n",
    "clf_grid = GridSearchCV(clf, params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "clf_grid.fit(train_feature_matrix, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We derive the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2:\n",
    "* What metric should be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3:\n",
    "* How many neighbors should be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4:\n",
    "* What type of strategy should be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aBmiDbvV25qI"
   },
   "source": [
    "Using the found optimal number of the neighbors, calculate the probabilities of belonging to the classes for the test sample(`.predict_proba`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ig_vS8O925qI"
   },
   "outputs": [],
   "source": [
    "optimal_clf = KNeighborsClassifier('''your code''')\n",
    "optimal_clf.fit('''your code''')\n",
    "pred_prob = optimal_clf.'''your code'''(test_feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "unique, freq = np.unique(test_labels, return_counts=True)\n",
    "freq = list(map(lambda x: x / len(test_labels),freq))\n",
    "\n",
    "pred_freq = pred_prob.mean(axis=0)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.bar(range(1, 8), pred_freq, width=0.4, align=\"edge\", label='prediction')\n",
    "plt.bar(range(1, 8), freq, width=-0.4, align=\"edge\", label='real')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5:\n",
    "* What is the predicted probability pred_freq of the optimal model of the class 3(round up to 2 decimal places)?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "dKCiU0wz25pj",
    "9MKHZ2JC25pv",
    "VYogShkD25qD",
    "p41xvYTU25qK"
   ],
   "default_view": {},
   "name": "HW1_Logistic_regression_and_SVM.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
