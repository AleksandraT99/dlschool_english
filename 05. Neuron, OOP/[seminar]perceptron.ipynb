{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uDI0ZLrS9jAX"
   },
   "source": [
    "<img src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\" width=500, height=450>\n",
    "<h3 style=\"text-align: center;\"><b>Phystech School of Applied Mathematics and Informatics (PSAMI) MIPT</b></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k0ygS84T9jAY"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HnjQZLuC9jAY"
   },
   "source": [
    "<h2 style=\"text-align: center;\"><b>Rosenblatt's perceptron<br><br>(neuron with threshold activation)</b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "543-uGN-9jAZ"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook you will learn how to:  \n",
    "\n",
    "- Implement class **`Perceptron()`** -- neuron with threshold activation\n",
    "- train and validate your perceptron on generated and real data (files with real data are in '/data' folder) \n",
    "- compare quality of your model with models from module `scikit-learn` (`sklearn.linear_model.Perceptron()`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cOAHk8eO9jAb"
   },
   "source": [
    "<h2 style=\"text-align: center;\"><b>Intro</b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bF22tUW79jAc"
   },
   "source": [
    "Almost every machine learning alghorithm solving either *classification* or *regression* problem works this way:\n",
    "\n",
    "1. (*initialization stage*) Human defines **Hyperparameters**, i.e. values which are not \"learned\" during training process \n",
    "2. (*training stage*) Algorithm is runned on data, **training** on it and tuning its **parameters** (don't confuse with *hyper*parameters) in some defined way (e.g., using *gradient decsend method* or *error correction method*), based on loss funtion. Loss function displays, how and where model is wrong\n",
    "3.  (*prediction stage*) Model is ready, and now we can make **predictions** on new data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3hxoVvmN9jAd"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jHd4CZjS9jAg"
   },
   "source": [
    "<h2 style=\"text-align: center;\"><b>Class Perceptron</b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PObIs0OB9jAh"
   },
   "source": [
    "In this section we will solve **binary classification** problem:  \n",
    "- *Input data*: matrix $X$ sized $(n, m)$ and column $y$ of zeros and ones sized $(n, 1)$. Rows of matrix correspond to objects, column - features (i.e. $i$ is a set of features (*feature description*) of an object $X_i$).\n",
    "- *Output data*: column $\\hat{y}$ of zeros and ones sized $(n, 1)$ - algorithm predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wkd_24Zr9jAi"
   },
   "source": [
    "Model of neuron in biology and deep learning:  \n",
    "\n",
    "![title](http://lamda.nju.edu.cn/weixs/project/CNNTricks/imgs/neuron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TwRqMBVPcy0j"
   },
   "source": [
    "\\**pic from http://cs231n.github.io/neural-networks-1/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "82qIny-49jAi"
   },
   "source": [
    "To understand how we will update weights of the model, we need to define loss funtion which we will minimize. In this case we have binary classification problem (classes are 0 and 1). Let's take **mean square error** as our loss function:  \n",
    "\n",
    "$$Loss(w, x) = \\frac{1}{2n}\\sum_{i=1}^{n} (\\hat{y_i} - y_i)^2 = \\frac{1}{2n}\\sum_{i=1}^{n} (f(w \\cdot X_i) - y_i)^2$$  \n",
    "\n",
    "Here $w \\cdot X_i$ - dot product, and $f(w \\cdot X_i)$ - threshold activation:  \n",
    "\n",
    "$$\n",
    "f(z) =\n",
    "\\begin{cases}\n",
    "1, &\\text{if } w \\cdot X_i > 0 \\\\\n",
    "0, &\\text{if } w \\cdot X_i \\le 0\n",
    "\\end{cases}\n",
    "$$  \n",
    "\n",
    "**Note:** It is supposed, that $b$ - free term - is a part of weights vector: $w_0$. So, if we add column of ones to the left side of $X$, we will get $b$ as a free term in dot product (figure out why it works on a piece of paper -- you will easily get it). But in our implementation of `Perceptron()` let's calculate $b$ separately (to make it clearer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6wGYvpsv9jAj"
   },
   "source": [
    "**Implement loss function $Loss$:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KIMPzh0B9jAk"
   },
   "outputs": [],
   "source": [
    "def Loss(y_pred, y):#numpy arrays as input(n = y.size)\n",
    "    return # Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5QrUrljB9jAn"
   },
   "source": [
    "Since out *threshold function* doesn't have a derivative (Have you seen its plot? It looks simple, but derivative doesn't think so), we can't use gradient decsent, after all:  \n",
    "\n",
    "\n",
    "\n",
    "$$ \\frac{\\partial Loss}{\\partial w} = \\frac{1}{n} X^T\\left(f(w \\cdot X) - y\\right)f'(w \\cdot X)$$  \n",
    "\n",
    "where $f^{'}(w \\cdot X)$ - can't be calculated in $x=0$. but we need to know how to update weights, else how to train algorithm to distinguish apples from pears?  \n",
    "\n",
    "So let's update weights with this rule:   \n",
    "\n",
    "$$w^{j+1} = w^{j} - \\alpha\\Delta{w^{j}}$$ \n",
    "\n",
    "where:  \n",
    "\n",
    "$$\\Delta{w} = \\frac{1}{n}X^T(\\hat{y} - y) = \\frac{1}{n}X^T(f(w^j \\cdot X) - y)$$  \n",
    "\n",
    "(don't forget, that with $w_0 = b$ feature $x_0$ = 1), where $w \\cdot X$ - matrix multiplication of column of weights $w$ with matrix of objects -features $X$, and index $j$ -- gradient descent iteration number.\n",
    "\n",
    "This rule is some special case of gradient descent for this case\n",
    "Это правило является неким частным случаем градиентного спуска для данного случая (*[Delta rule](https://en.wikipedia.org/wiki/Delta_rule)*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zrm01BR69jAo"
   },
   "source": [
    "Now we finally ready to write our own **`Perceptron()`**. Here is some code as a backbone. Try to use **Numpy** as much as you can since it is faster than simple python arithmetics.\n",
    "\n",
    "*Note*: In code below `y_pred` is $\\hat{y}$ from formulas above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rLBDN2G89jAo"
   },
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, w=None, b=0):\n",
    "        \"\"\"\n",
    "        :param: w -- weights vector\n",
    "        :param: b -- bias scalar\n",
    "        \"\"\"\n",
    "        # Let's leave an opportunity for a user to set weights and biases directly\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        \n",
    "    def activate(self, x):\n",
    "        # You code here\n",
    "        \n",
    "    def forward_pass(self, X):\n",
    "        \"\"\"\n",
    "        This function computes an answer of the perceptron given a set of objects\n",
    "        :param: X -- matrix of objects sized (n, m), every row - separate object\n",
    "        :return: vector sized (n, 1) of zeros and ones containing model answers \n",
    "        \"\"\"\n",
    "        # You code here\n",
    "    \n",
    "    def backward_pass(self, X, y, y_pred, learning_rate=0.005):\n",
    "        \"\"\"\n",
    "        Updates weights values given objects\n",
    "        :param: X -- matrix of objects sized (n, m)\n",
    "                y -- right answers vector sized (n, 1)\n",
    "                learning_rate - \"speed of learning\" (symbol alpha in formulas above)\n",
    "        This method doesn't return anything, it only corrects weights using gradient\n",
    "        descend.\n",
    "        \"\"\"\n",
    "        \n",
    "        # You code here\n",
    "    \n",
    "    def fit(self, X, y, num_epochs=300):\n",
    "        \"\"\"\n",
    "        Descend in a minimum\n",
    "        :param: X -- matrix of objects sized (n, m)\n",
    "                y -- right answers vector sized (n, 1)\n",
    "                num_epochs -- number of training steps\n",
    "        :return: Loss_values -- vector of loss values\n",
    "        \"\"\"\n",
    "        self.w = np.zeros((X.shape[1], 1))  # column (m, 1)\n",
    "        self.b = 0  # bias (free term)\n",
    "        losses = []  # loss values on every step of fitting\n",
    "        \n",
    "        # You code here\n",
    "        # for i in range(num_epochs):\n",
    "        \n",
    "        return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XlWXLoHQ9jAr"
   },
   "source": [
    "Class is ready. Let's check, if the code is right. Below are several cells with test code. Your goal is to check if results match with answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GnrccB6H9jAs"
   },
   "source": [
    "**Check forward_pass():**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 551,
     "status": "ok",
     "timestamp": 1539450353886,
     "user": {
      "displayName": "Маза Факер",
      "photoUrl": "",
      "userId": "00428038539447448724"
     },
     "user_tz": -180
    },
    "id": "9LZgkcHv9jAt",
    "outputId": "59bd0c97-a549-476f-9fb1-243b1ae07ef6"
   },
   "outputs": [],
   "source": [
    "w = np.array([1., 2.]).reshape(2, 1)\n",
    "b = 2.\n",
    "X = np.array([[1., 2., -1.], [3., 4., -3.2]])\n",
    "\n",
    "perceptron = Perceptron(w, b)\n",
    "y_pred = perceptron.forward_pass(X.T)\n",
    "print (\"y_pred = \" + str(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RlPOE9ia9jAv"
   },
   "source": [
    "|Must be||\n",
    "|------|-------|\n",
    "|**y_pred**|[1, 1, 0]|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1rgBqV9D9jAv"
   },
   "source": [
    "**Check backward_pass():**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9RkAnK0P9jAw"
   },
   "outputs": [],
   "source": [
    "y = np.array([1, 0, 1]).reshape(3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 612,
     "status": "ok",
     "timestamp": 1539450382319,
     "user": {
      "displayName": "Sir. Klop300channel",
      "photoUrl": "",
      "userId": "17461207290813147689"
     },
     "user_tz": -180
    },
    "id": "Be7OJp8c9jA1",
    "outputId": "67b51d16-7a2b-4a75-d649-c25169bfcec9"
   },
   "outputs": [],
   "source": [
    "perceptron.backward_pass(X.T, y, y_pred)\n",
    "\n",
    "print (\"w = \" + str(perceptron.w))\n",
    "print (\"b = \" + str(perceptron.b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nNThF8MT9jA4"
   },
   "source": [
    "|Must be||\n",
    "|-|-|\n",
    "|**w**| [[ 0.995], [1.988]] |\n",
    "|**b**| 2.0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EDjsmpZp9jA5"
   },
   "source": [
    "Let's check how loss function changees during learning process on real data - dataset \"Apples and pears\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 900
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 598,
     "status": "error",
     "timestamp": 1539450431613,
     "user": {
      "displayName": "Sir. Klop300channel",
      "photoUrl": "",
      "userId": "17461207290813147689"
     },
     "user_tz": -180
    },
    "id": "aPzhL2L99jA5",
    "outputId": "ec67cd75-7d6e-4699-ee31-14c06f54e15b"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/apples_pears.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 680,
     "status": "error",
     "timestamp": 1539450471450,
     "user": {
      "displayName": "BrainsExplotion",
      "photoUrl": "",
      "userId": "13698855170200822423"
     },
     "user_tz": -180
    },
    "id": "q7cWGg5S9jA7",
    "outputId": "bb042b57-e5ad-494e-a507-8f74dcb20dd0"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1184,
     "status": "error",
     "timestamp": 1539448612121,
     "user": {
      "displayName": "Кирилл Куликов",
      "photoUrl": "",
      "userId": "13750676750728975449"
     },
     "user_tz": -180
    },
    "id": "V6T8WK2w9jA-",
    "outputId": "6f5f394b-8d31-43c9-f659-2ed7e9a96c34"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(data.iloc[:, 0], data.iloc[:, 1], c=data['target'], cmap='rainbow')\n",
    "plt.title('Apples and pears', fontsize=15)\n",
    "plt.xlabel('simmetry', fontsize=14)\n",
    "plt.ylabel('yellowness', fontsize=14)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JYSpUvQM9jBE"
   },
   "source": [
    "**Question:** Which class correspons to apples (which color are they on the plot)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MO0fW5R29jBF"
   },
   "source": [
    "**Answer:** < Your answer >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X6m0IAdu9jBF"
   },
   "source": [
    "Extract questions(features) and answers(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ARYN13Io9jBG"
   },
   "outputs": [],
   "source": [
    "X = data.iloc[:,:2].values  # matrix of objects-features\n",
    "y = data['target'].values.reshape((-1, 1))  # classes (column of zeros and ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MRCQeKtH9jBI"
   },
   "source": [
    "**Loss plot**  \n",
    "Loss function should decrease and as a result is should be close to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sIR0g6mQ9jBJ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "perceptron = # Your code here\n",
    "losses = # Your code here\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(losses)\n",
    "plt.title('Loss function', fontsize=15)\n",
    "plt.xlabel('Iteration number', fontsize=14)\n",
    "plt.ylabel('$Loss(\\hat{y}, y)$', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gnzSyV_j9jBN"
   },
   "source": [
    "Let's see how perceptron classifies objects from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bNhsJbuY9jBO"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(data.iloc[:, 0], data.iloc[:, 1], c=perceptron.forward_pass(X).ravel(), cmap='spring')\n",
    "plt.title('Apples and pears', fontsize=15)\n",
    "plt.xlabel('symmetry', fontsize=14)\n",
    "plt.ylabel('yellowness', fontsize=14)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It worked perfect. However, note that this is very easy linear-separated data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aE8iMuT39jBQ"
   },
   "source": [
    "<h3 style=\"text-align: center;\"><b>Gender recognition by voice</b></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hQHD1i1W9jBR"
   },
   "source": [
    "In this task we are going to compare quality of our perceptron to an algorithm from a framework called `sklearn` on a dataset from website [Kaggle](https://www.kaggle.com) - [Gender Recognition by Voice](https://www.kaggle.com/primaryobjects/voicegender). In this dataset features are various characteristics of human voice and there are two classes - gender of a speaker (man/woman). You can learn more from [the page of dataset](https://www.kaggle.com/primaryobjects/voicegender). Our goal is just to compare theese 2 alghorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2duv7On99jBR"
   },
   "source": [
    "**! Notice, the name of the class from sklearn is skPerceptron** (it's imported with different name in order to avoid name collision with our class Perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YaLaxBHR9jBS"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import Perceptron as skPerceptron\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 936
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 625,
     "status": "error",
     "timestamp": 1539451209225,
     "user": {
      "displayName": "Sir. Klop300channel",
      "photoUrl": "",
      "userId": "17461207290813147689"
     },
     "user_tz": -180
    },
    "id": "IaNjHU7Q9jBU",
    "outputId": "ff3a76eb-da48-464e-95bd-d343fb260d16"
   },
   "outputs": [],
   "source": [
    "data_path = './data/voice.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "data['label'] = data['label'].apply(lambda x: 1 if x == 'male' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eU1EZFzM9jBW"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QCSK3sfX9jBY"
   },
   "outputs": [],
   "source": [
    "# Shuffle the data - data is sorted by column 'label' in the file\n",
    "data = data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VKY1jHT79jBZ"
   },
   "outputs": [],
   "source": [
    "X_train = data.iloc[:int(len(data)*0.7), :-1]  # matrix objects-features\n",
    "y_train = data.iloc[:int(len(data)*0.7), -1]  # ground-true label (man/woman)\n",
    "\n",
    "X_test = data.iloc[int(len(data)*0.7):, :-1]  # matrix objects-features\n",
    "y_test = data.iloc[int(len(data)*0.7):, -1]  # ground-true label (man/woman)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DDsWavYZ9jBe"
   },
   "source": [
    "Here we train our perceptron and perceptron from `sklearn` on this data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Z8Rh-bu9jBf"
   },
   "outputs": [],
   "source": [
    "perceptron_sk = skPerceptron()\n",
    "perceptron_my = Perceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 189
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 615,
     "status": "error",
     "timestamp": 1539451527244,
     "user": {
      "displayName": "Sir. Klop300channel",
      "photoUrl": "",
      "userId": "17461207290813147689"
     },
     "user_tz": -180
    },
    "id": "QvqZQfG8c25F",
    "outputId": "12624002-2e70-4664-8d4d-287f8e9e065d"
   },
   "outputs": [],
   "source": [
    "perceptron_sk.fit(X.train.values, y.train.values)\n",
    "perceptron_my.fit(X.train.values, y.train.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3qsolz149jBh"
   },
   "source": [
    "Let's check their accuracy on test part of dataset<br>\n",
    "Here by **accuracy** we understand (right answers / all answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 703,
     "status": "error",
     "timestamp": 1539448636600,
     "user": {
      "displayName": "Кирилл Куликов",
      "photoUrl": "",
      "userId": "13750676750728975449"
     },
     "user_tz": -180
    },
    "id": "l6R3cXLO9jBi",
    "outputId": "cbb39ebe-965e-407e-ff55-6e5bf388667e"
   },
   "outputs": [],
   "source": [
    "print('Accuracy of our perceptron: {:d}'.format(accuracy_score(<Your code here>) * 100))\n",
    "print('Accuracy of perceptron from sklearn: {:.1f} %'.format(accuracy_score(<Your code here>) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CSasTfW09jBj"
   },
   "source": [
    "**Question:** Does perceptron show good results? What is your opinion why? You can answer any thoughts on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uWaJ-92j9jBj"
   },
   "source": [
    "**Answer:**< Your answer >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yyX2G7VvdvMC"
   },
   "source": [
    "### Important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sTZFLUqFdv57"
   },
   "source": [
    "Worth mentioning that perceptron isn't realy used in practical applications. We demonstrated it to you to show you, what is the origin of current state-of-the-art model. Actually one neuron with threshold activation funtion is neither used in multilayer neural networks or any real applications. However it plays an important role in learning how weights of the models update given errors and lets us to introduce you to much more useful neuron with other **smooth activation functions**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MC0FNrfq9jBl"
   },
   "source": [
    "<h2 style=\"text-align: center;\"><b>Useful links</b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AZLMhq149jBl"
   },
   "source": [
    "1). Lecture Notes of Stanford university: http://cs231n.github.io/neural-networks-1/  \n",
    "2). [Wikipedia about perceptron](https://en.wikipedia.org/wiki/Perceptron)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "[seminar]perceptron.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
